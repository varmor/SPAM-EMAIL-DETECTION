{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a945002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c908a3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     Subject: naturally irresistible your corporate...     1\n",
       "1     Subject: the stock trading gunslinger  fanny i...     1\n",
       "2     Subject: unbelievable new homes made easy  im ...     1\n",
       "3     Subject: 4 color printing special  request add...     1\n",
       "4     Subject: do not have money , get software cds ...     1\n",
       "...                                                 ...   ...\n",
       "5690  Subject: re : research and development charges...     0\n",
       "5691  Subject: re : receipts from visit  jim ,  than...     0\n",
       "5692  Subject: re : enron case study update  wow ! a...     0\n",
       "5693  Subject: re : interest  david ,  please , call...     0\n",
       "5694  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
       "\n",
       "[5695 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Dataset/email-dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c107e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../src/email-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7821738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8e4ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c439ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e29790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "spam    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c6dd0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56a3375c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean\n",
    "# to show the tokenization\n",
    "df['text'].head().apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c255f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472caff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = cv.fit_transform(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc39972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(message, df['spam'], test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80395072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# createing and training the SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_classifier = SVC(kernel = \"rbf\", random_state = 0)\n",
    "SVM_classifier.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc47891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(SVM_classifier.predict(xtrain))\n",
    "print(ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe5b7285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3457\n",
      "           1       0.99      0.87      0.92      1099\n",
      "\n",
      "    accuracy                           0.97      4556\n",
      "   macro avg       0.97      0.93      0.95      4556\n",
      "weighted avg       0.97      0.97      0.96      4556\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3446   11]\n",
      " [ 148  951]]\n",
      "Accuracy: \n",
      " 0.9651009657594382\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the SVM Classifier model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = SVM_classifier.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaff2b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(SVM_classifier.predict(xtest))\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "161275e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       870\n",
      "           1       0.97      0.82      0.89       269\n",
      "\n",
      "    accuracy                           0.95      1139\n",
      "   macro avg       0.96      0.91      0.93      1139\n",
      "weighted avg       0.95      0.95      0.95      1139\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[864   6]\n",
      " [ 49 220]]\n",
      "Accuracy: \n",
      " 0.95171202809482\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the SVM Classifier model on the test data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = SVM_classifier.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7899f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and training the Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb57b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(xtrain))\n",
    "print(ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f1b7dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3457\n",
      "           1       0.99      1.00      0.99      1099\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       0.99      1.00      0.99      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3441   16]\n",
      " [   1 1098]]\n",
      "Accuracy: \n",
      " 0.996268656716418\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Naive Bayes Classifier model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf35b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(xtest))\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90e77c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       870\n",
      "           1       0.97      1.00      0.98       269\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[861   9]\n",
      " [  1 268]]\n",
      "Accuracy: \n",
      " 0.9912203687445127\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the Naive Bayes Classifier model on the test data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e1d8e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "978e6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "testt = process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2501f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = cv.transform(testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30a8dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(message)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47a233c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a3da511",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../classifier.pkl\", \"wb\")as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b84af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../vectorizer.pkl\", \"wb\") as v:\n",
    "    pickle.dump(cv, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaaf9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../classifier.pkl\", \"rb\")as f:\n",
    "    classi = pickle.load(f)\n",
    "    \n",
    "with open(\"../vectorizer.pkl\", \"rb\") as v:\n",
    "    cvv = pickle.load(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9765e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '''1 new job for 'full stack engineer'\n",
    "     Your job alert for full stack engineer\n",
    "1 new job in Pune, Maharashtra, India matches your preferences.\n",
    "\n",
    "DoorMonk\t\n",
    "Full Stack Engineer\n",
    "DoorMonk Â· Pune, Maharashtra, India (Remote)\n",
    "\n",
    "See all jobs\n",
    " \n",
    "premium\n",
    "Varun More\n",
    "See jobs where you're a top applicant\n",
    "Try Premium for free\n",
    " \n",
    " \n",
    " \n",
    "This email was intended for Varun More (ðŸ’»Computer Science + ðŸ§ Artificial Intelligence | Python, C++, C Programming, JavaScript | GSSoC'22). Learn why we included this.\n",
    "\n",
    " \n",
    "You are receiving Job Alert emails.\n",
    "\n",
    "Manage job alerts  Â·  Unsubscribe  Â·  Help\n",
    "LinkedIn\n",
    " \n",
    "Â© 2022 LinkedIn Ireland Unlimited Company, Wilton Plaza, Wilton Place, Dublin 2. LinkedIn is a registered business name of LinkedIn Ireland Unlimited Company. LinkedIn and the LinkedIn logo are registered trademarks of LinkedIn.\n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbbbf4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7335cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_m = cvv.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d120aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(classi.predict(test_text_m)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7fa91",
   "metadata": {},
   "source": [
    "Accuracy for Support Vector Machine Classifier is _0.9651009657594382_ on traning dataset.\n",
    "\n",
    "Accuracy for Support Vector Machine Classifier is _0.95171202809482_ on test dataset.\n",
    "\n",
    "\n",
    "Accuracy for Multinomial Naive Bayes Classifier is _0.996268656716418_ on traning dataset.\n",
    "\n",
    "Accuracy for Multinomial Naive Bayes Classifier is _0.9912203687445127_ on test dataset.\n",
    "\n",
    "Since the accuracy of Multinomial Naive Bayes Classifier is more, so we decided to go with Multinomial Naive Bayes Classifier for this problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f8dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
